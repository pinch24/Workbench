[Software Engineering at Google by Titus Winters / Tom Manshreck / Hyrax Wright, 2020 ]()

## 추천사
[By Camille Fournier]()

그들은 어떻게 그토록 거대한 단일 코드 리포지터리를 중단 없이 운영할 수 있을까요? 수만 명의 엔지니어가 수천 개의 프로젝트에서 성공적으로 협업해가는 비결은 무엇이며, 그 많은 시스템의 품질을 안정되게 유지하는 비결은 무엇일까요?

‘오픈 소스로부터 쉽게 취할 수 있는 기능은 무엇인가?’, ‘직접 개발하는 편이 나은 것인가?’, ‘우리 규모에 적합한 선택은 무엇일까?’

여러분이 또 하나의 구글을 만들 필요는 없습니다… 하지만 구글이 발전시켜온 숱한 노하우들을 모른다면, 여러분은 수만 명의 엔지니어가 20년 넘게 조화를 이뤄 다듬어온 소프트웨어 엔지니어링 지식을 놓치게 됩니다. 모른 척 하기에는 너무나 값진 지식일 것입니다.

## 들어가며
소프트웨어 엔지니어링을 ‘프로그래밍’이나 ‘컴퓨터 과학’과 구분 짓는 특징은 무엇일까요?

**‘프로그래밍’**과 ‘**소프트웨어 엔지니어링’**은 서로 강조하는 것도 다르고 영향을 미치는 영역도 다릅니다. 하지만 우리 업계는 꽤 오랫동안 둘을 명확히 구분하지 않고 사용해왔습니다. 대학생들이 컴퓨터 과학을 공부한 후, 사회에 나와서는 코드를 짜는 ‘프로그래머’가 되는 식이었죠.

하지만 ‘소프트웨어 엔지니어링’이라는 용어는 좀 더 진중하다는 느낌을 줍니다. **무언가를 실제로 그리고 정확하게 구현하기 위해 어떤 이론적인 지식을 적용해야 할 것**만 같죠. 기계 엔지니어, 토목 엔지니어, 항공 엔지니어 같은 다른 엔지니어링 분야의 엔지니어들은 모두 공학적인 무언가를 훈련받기도 합니다. **그들은 모두 현실 세계에서 일하고 이론적인 지식을 적용하여 실제로 무언가를 만들어냅니다.** 물론 소프트웨어 엔지니어도 ‘무언가를 실제로’ 만듭니다. 다른 분야 엔지니어들이 만드는 것처럼 손으로 만져볼 수는 없지만 말이죠.

기존의 다른 엔지니어링 직업들과 달리 **소프트웨어 엔지니어링 이론과 관례는 그리 엄격하지 않습니다.** 항공 엔지니어는 계산을 실수하면 막대한 피해로 이어지기 때문에 엄격한 지침과 관례를 따라야 합니다. **프로그래밍에서는 대체로 엄격함의 정도가 훨씬 낮은 편이었습니다.** 하지만 **소프트웨어가 우리 삶에 깊숙이 파고들면서 우리도 더 엄격한 엔지니어링 방법을 채택하고 따라야 하는 시대가 도래했습니다.**

## 시간 위를 걷는 프로그래밍
**소프트웨어 엔지니어링\_software engineering\_**은 단순히 **코드를 작성하는 행위**에 더하여, **시간의 흐름**에 발맞춰 한 **조직이 그 코드를 구축하고 유지보수**하는 데 이용하는 모든 **도구와 프로세스**를 포괄합니다.

이 책을 통해 공유하고자 하는 핵심은 소프트웨어 엔지니어링이란 **‘흐르는 시간 위에서 순간순간의 프로그래밍을 모두 합산한 것이다.\_programming integrated over time\_’**라는 관점입니다. **개념잡기, 도입, 유지보수, 폐기에 이르는 생애주기** 동안 코드를 **지속 가능\_sustainable\_하게 (필요한 변경 요청에 대응할 수 있게)** 하려면 코드에 어떤 관례를 도입해야 할까요?

이 책은 **소프트웨어 조직**이 **설계, 아키텍처 잡기, 코드 작성 시** 명심해야 한다고 믿는 세 가지 **기본 원칙**을 강조합니다.
- **시간\_time\_과 변경\_change\_**: 코드가 수명을 다할 때까지 새로운 요구사항에 잘 적응하려면 어떻게 해야 하는가?
- **규모\_scale\_와 성장\_growth\_**: 커져가는 규모에 발맞춰 조직은 어떻게 진화해야 하는가?
- **트레이드오프\_tradeoff\_와 비용\_cost\_**: ‘시간과 변경’, ‘규모와 성장’에서 얻은 교훈들을 바탕으로 조직은 어떻게 의사결정을 내려야 하는가?

## 구글의 시각
[By Tom Manshreck]()
구글이 소프트웨어 엔지니어링을 바라보는 주된 시각에 따라 이 책의 주제를 세 가지로 나누었습니다.
- 문화
- 프로세스
- 도구

이 책은 **우리의 시각**입니다. 하지만 그대로 적용하든 혹은 여러분의 조직이 고민하는 문제 영역에 특화된 독자적인 관례를 논하는 시발점으로 활용하든, 부디 유용한 책이 되기를 희망합니다.

설교하려는 의도도 전혀 없습니다. 구글 스스로도 이 책에서 소개한 많은 개념을 완벽히 뿌리내리지 못하고 있습니다. 지금까지 배운 교훈은 모두 숱한 실패 끝에 터득했습니다. **우리는 여전히 실수하고, 불완전한 제품을 내놓고, 전진하기 위해 또다시 반복해야 합니다.** 그렇더라도 구글 엔지니어링의 엄청난 규모는 수많은 문제에 대처하는 다양한 해법을 제시하기에 충분할 것입니다. 부디 우리가 구글에서 가장 뛰어난 점들을 잘 추려 담아냈기를 소망합니다.

# Part 1. 전제
# Chapter 1. 소프트웨어 엔지니어링이란?
> 바위 위에 지어지는 것은 없습니다. 모든 것은 모래 위에 지어지죠. 하지만 우리는 모래가 바위라고 생각하고 지어야 합니다.  
> [by 호르헤 루이스 보르헤스]()

프로그래밍과 소프트웨어 엔지니어링의 가장 큰 차이는 시간\_time_, 확장\_scale_, 트레이드오프\_trade-off\_, 이렇게 세 가지라고 생각한다. 소프트웨어 엔지니어링 **프로젝트**에서 엔지니어는 시간의 흐름과 언젠가 변경\_change\_될 가능성에 더 신경 써야 한다. 소프트웨어 엔지니어링 **조직**은 만들어낼 소프트웨어 자체뿐 아니라 제작하는 조직까지 양 측면 모두에서의 확장과 효율에 더 집중해야 한다. 마지막으로 소프트웨어 **엔지니어**는 대체로 수명과 성장 속도를 정밀하게 예측하기 어려운 상황에서, 결과에 더 큰 영향을 주는 보다 복잡한 결정을 내려야 한다.

구글에서는 이따금 ‘소프트웨어 엔지니어링은 흐르는 시간 위에서 순간순간의 프로그래밍을 모두 합산한 것이다\_Software engineering is programming integrated over time\_’라고 말하곤 한다. 소프트웨어 엔지니어링에서 프로그래밍이 큰 비중을 차지하는 건 틀림없지만 프로그래밍은 결국 새로운 소프트웨어를 제작하는 수단이다. 이 차이를 받아들인다면 자연스럽게 프로그래밍 작업(개발,\_development_)과 소프트웨어 엔지니어링 작업(개발\_development_ + 수정\_modification\_ + 유지보수\_maintenance\_)의 차이도 궁금할 것이다. **시간**이라는 요소가 더해지면서 프로그래밍에는 중요한 차원이 하나 늘어서 더 입체적으로 바뀐다. 정육면체는 정사각형이 아니고 거리는 속도가 아니듯, 소프트웨어 엔지니어링은 프로그래밍이 아닌 것이다.

시간이 프로그램에 미치는 영향을 알아보려면 **‘이 코드의 예상 수명은?’**이라는 질문을 던져보면 좋다.(단순한 구동 수명\_execution lifetime\_이 아니라 유지보수 수명\_maintenance lifetime\_을 말한다. 즉, 이 코드가 언제까지 개발, 구동, 유지보수될 것인지, 혹은 이 소프트웨어의 가치가 언제까지 유효할지를 묻는 질문이다.) 답변은 천차만별일 것이다. 몇 분 후면 사라질 코드부터 수십 년을 살아남을 코드까지 다양한 경우를 상상해볼 수 있다. 짧게 생을 마감하는 코드는 대체로 시간의 영향을 받지 않는다. 반면 기반 라이브러리, 운영체제, 하드웨어, 프로그래밍 언어를 겨우 한 시간 만에 바꾸는 일은 없다. 정육면체를 극단적으로 압축하면 정사각형이 되듯, **단명하는 시스템은 ‘그저’ 프로그래밍 문제와 다를 게 없다. 하지만 수명이 길어질수록 변경이라는 요소가 점점 중요해진다.** 십 년 이상 살아남는다면 간접적이든 직접적이든 프로그램의 거의 모든 의존성(외부 라이브러리, 기반 프레임워크, 운영체제 등)이 처음과는 달라질 것이다. **우리가 생각하는 소프트웨어 엔지니어링과 프로그래밍을 가르는 핵심은 이 사실을 인식하는 데서 시작한다.**

이 차이가 우리가 말하는 소프트웨어의 **지속 가능성\_sustainability\_**의 핵심이다. 기술적인 이유든 사업적인 이유든, **소프트웨어의 기대 생에 동안 요구되는 모든 가치 있는 변경에 대응할 수 있다면 ‘그 프로젝트는 지속 가능하다’라고 말한다.** 여기서 중요한 것은 **역량만을 따진다**는 점이다. 즉, 가치가 충분치 않거나 더 중요한 일을 위해 해당 변경을 진행하지 않기로 선택할 수도 있다.(**기술 부채\_technical debt\_**의 다른 정의로 볼 수 있다. **기술 부채란 ‘해야 할’ 일을 아직 하지 않은 것**을 말하며, 따라서 **코드에 ‘바라는 모습’과 ‘현재 모습’의 차이만큼이 기술 부채의 크기**가 된다.) 기반 기술이나 제품이 지향하는 길로 나아가는 데 필요한 잠재적인 변경에 대응할 역량 자체가 없다면 어떨까? 그 변경이 정말로 중요해질 일이 없기를 바라며 위험한 베팅을 하는 꼴이다. 단명하는 프로젝트에서는 안전한 베팅일 수 있지만, 수십 년짜리 프로젝트에서는 그렇지 않을 것이다.(오래 살아남을 프로젝트인지를 미리 알고 있는가에 관한 문제도 고려해야 한다.)

이번에는 소프트웨어 엔지니어링을 **‘규모’**라는 관점에서 바라보자. **‘몇 명이 참여하는가?’, ‘시간의 흐름에 따라 엔지니어들은 개발과 유지보수의 어느 부분에 관여하는가?’** 소프트웨어 작업 하나는 대체로 개인 창작이지만, 소프트웨어 엔지니어링을 ‘여러 버전의 프로그램을 여러 사람이 참여해 개발하는 것\_The multiperson development of multiversion programs\_’이라고 정의하곤 했다. 팀 업무라는 관점을 잘 녹여냈다. 이 정의에 의하면 **소프트웨어 엔지니어링과 프로그램은 시간과 참여 인원 면에서 차이가 난다. 협업은 그 자체로 새로운 문제를 유발하지만, 한 명이 개발하는 것보다 가치 있는 시스템을 만들어낼 잠재력 또한 지닌다.**

소프트웨어 프로젝트의 **팀 조직, 프로젝트 구성, 정책과 관례**는 모두 소프트웨어 엔지니어링의 **복잡성을 좌우**한다. 그리고 이 문제들 모두 규모와 관련이 깊다. **‘조직이 성장하고 프로젝트가 확장될수록 소프트웨어 생산 효율도 높아지는가?’, ‘개발 워크플로의 효율도 우리의 성장에 발맞춰 개선되는가?’, 혹은 ‘우리가 따르는 버전 관리 정책과 테스트 전략이 조직 규모가 확장되면 비례하여 비용을 증가시키는가?’** 규모에 따른 소통 문제와 인력 충원 문제는 소프트웨어 엔지니어링 초창기부터 논의되어 온 주제이다.(맨먼스 미신) **프로젝트나 조직 규모가 확장되며 딸려오는 문제는 흔히 정책에 영향을 주며, ‘반복 수행하는 일들에 비용을 얼마나 쓸 것인가?’ 같은 소프트웨어의 지속 가능성을 묻는 질문에 답하는 기초가 된다.**

소프트웨어 엔지니어링은 또한 의사결저으이 복잡성과 이해관계 측면에서도 프로그래밍과 차이가 난다. 소프트웨어 엔지니어링에서는 주기적으로 **여러 선택지 사이의 트레이드오프를 평가**해야 한다. 때로는 불완전한 지표에 기대어 결과에 커다란 영향을 주는 선택을 해야만 한다. 소프트웨어 엔지니어 혹은 리더는 **지속 가능성을 잃지 않으면서 조직, 제품, 개발 워크플로의 규모를 확장하는 비용을 관리해야 한다.** 이러한 사실을 주지하고 **트레이드오프를 평가**하여 **합리적인 결정**을 내려야 한다. **때로는 유지보수에 도움되는 변경을 연기하거나 심지어 확장성이 떨어지는 정책을 받아들여야 할 때도 있다.** 이러한 결정은 **훗날 다시 검토**해야 할 수 있음을 잊지 말아야 하며, 이 결정 때문에 생긴 **지연 비용**을 정확히 계산해두어야 한다.

이 책을 ‘규모가 커질수록 효과도 커지는 엔지니어링 생태계에 관한 보고서’라고 생각하기를 바란다. … 바라건대, 여러분 조직이 이 비용까지 걱정할 만큼 성장한다면 우리보다 더 나은 답을 찾게 될 것이다.

## 1.1 시간과 변경
초심자가 프로그래밍을 배우는 과정에서 작성한 코드의 수명은 보통 몇 시간에서 며칠 정도 일 것이다. 프로그래밍 과제와 연습문제용 코드는 한 번 작성된 뒤로는 거의 리팩토링할 일이 없다. 오랫동안 유지보수하는 일은 더욱 상상할 수 없다. 처음 작성한 뒤로는 다시 빌드되거나 다시 실행될 가능성조차 희박하다. 프로그래밍을 처음 배울 때 흔히 발생하는 일이다.

현업에서도 **단명하는 코드**를 다루는 개발자를 찾을 수 있다. **모바일 앱의 수명은 다소 짧은 편이며 좋든 싫든 코드 전체를 처음부터 새로 작성하는 비율도 상대적으로 높다. 초기 단계의 스타트업에서 일하는 엔지니어들도 장기적인 투자보다는 바로 눈앞의 목표에 집중하려 할 것이다. 기반 구조를 닦는 데 투자한 비용이 회수되기 시작할 때까지 회사가 살아남지 못 할 가능성이 크기 때문이다.** 그래서 줄곧 초기 스타트업에서만 일해왔다면 10년 차 개발자라도 소프트웨어를 1\~2년 이상 유지보수해본 경험이 전무할 수 있다.

반대편 끝에는 **반영구적으로 살아남는 성공한 프로젝트**도 있다. 구글 검색, 리눅스 커널, 아파치 HTTP 서버의 수명이 언제 다할지를 합리적인 방법으로 예측할 수 있을까? 구글에서 진행하는 프로젝트는 대부분 영원히 생존하리라 가정해야 한다. 즉, 의존성이나 언어 버전 업그레이드가 필요 없어지는 시기를 예측할 수 없다. 생존 기간이 길어지면 이러한 장수 프로젝트들은 단순한 프로그래밍 과제나 스타트업 개발과는 다른 무언가가 되어 간다.

소프트웨어 프로젝트의 **‘기대 수명\_expected life span\_’**과 업그레이드 중요도의 관계는 기대 수명 스펙트럼의 최저점과 최고점 사이에서 일회성 프로그램과 수십 년을 지속하는 프로젝트 사이에서 **전환 시점**이 발생하는데, 이를 기점으로 **프로젝트는 외부 환경의 변화에 대비하기 시작**해야 한다.(**정확한 시점은 우선순위와 선호도에 따라 달라진다**. 경험상 대부분의 프로젝트는 5년 이내에 업그레이드를 했다. 이에 기초하여 예측해보자면, 전환 시점은 대체로 5\~10년 사이 어딘가일 것이다.)

초기부터 **업그레이드를 계획하지 않은 프로젝트라면** 이 전환이 아주 고통스러울 것이다. 이유는 다음 세가지로, 서로가 밀접하게 관련되어 있다.
- 해당 프로젝트에서 **수행해본 적 없는 작업을 진행**해야 한다. 따라서 **꼭꼭 숨어 있던 가정들이 수면 위로 드러나게 된다.**
- 업그레이드 담당 엔지니어들이 **이런 종류의 작업을 경험해보지 못했을 가능성**이 크다.
- 일반적인 업그레이드보다 **작업 규모가 큰 경우**가 많다. 점진적으로 업그레이드하는 것이 아니라, 수년 치 업그레이드를 한 번에 진행해야 하기 때문이다.

그래서 업그레이드에 성공하든 중도에 포기하든, 이런 고통을 한 번 겪고 나면 지레 겁먹고 이후의 업그레이드 비용을 과대 측정하여 ‘다시는 시도하지 않겠다’라고 다짐하기도 한다. 이런 결론에 이른 회사는 기존 코드를 버리고 새로 작성하거나 업그레이드를 완전히 포기해버리곤 한다. 하지만 이처럼 고통을 회피하는 방안보다는 고통을 덜어줄 방법을 찾는 것이 때로는 더 합리적일 것이다. **어느 선택이 옳은지는 전적으로 업그레이드 비용, 업그레이드가 가져다 줄 이익, 프로젝트의 기대 수명에 달려 있다.**

첫 대규모 업그레이드를 성공적으로 마치는 일뿐 아니라 현재 상태를 안정되게 유지할 수도 있어야만 프로젝트가 오래 지속 가능할 확률이 높아진다. **지속 가능하게 하려면 요구되는 변경들의 영향을 계획하고 관리해야 한다.** 구글의 프로젝트들도 수많은 시행착오를 거쳐 지금 수준의 **지속 가능성**에 도달할 수 있었다.

그렇다면 단명하는 프로그램용 코드와 수명이 훨씬 긴 프로젝트가 만들어내는 코드는 구체적으로 어떻게 다를까? **수명이 길어질수록 ‘동작한다’와 ‘유지보수 가능하다’의 차이를 더 분명하게 인지해야 한다.** 불행히도 둘을 구분하는 완벽한 해법은 없다. 소프트웨어를 장기간 유지보수하는 일은 끝나지 않는 전쟁이기 때문이다.

### 1.1.1 하이럼의 법칙
> **하이럼의 법칙\_Hyrum’s Law\_**: API 사용자가 충분히 많다면 API 명세에 적힌 내용은 중요하지 않다. 시스템에서 눈에 보이는 모든 동작을 누군가는 이용하게 될 것이기 때문이다.

하이럼의 법칙은 ‘암시적 의존성 법칙\_The Law of Implicit Dependencies\_’라고 불리지만 거의 ‘하이럼의 법칙’으로 통용된다.

하이럼의 법칙은 **시간의 흐름에 따른 소프트웨어 변경 문제(유지 보수)**와 관련한 모든 논의에서 지배적인 요인이었다. 그러나 소프트웨어 유지보수에 하이럼의 법칙이 적용된다고 해서 계획 세우기를 등한시하거나 소프트웨어를 더 잘 이해하려는 노력을 포기해서는 안 된다. **문제를 완벽하게 제거할 수는 없더라도 완화할 수는** 있기 때문이다.

하이럼의 법칙은 **최선의 의도, 최고의 엔지니어, 꼼꼼한 코드 리뷰가 뒷받침되더라도 공표한 계약(명세)이나 모범 사례를 완벽하게 구현해냈다고 단정할 수 없다**는 현실을 표현한 말이다. API 소유자는 인터페이스를 명확하게 설명해놓으면 어느 정도의 유연성과 자유를 얻을 수 있다. 하지만 현실에서는 API 사용자가 (명세에는 없는) 기능을 찾아 활용하기도 하며, 그 기능이 유용해 널리 쓰이면 추후 API를 변경하기 어렵게 된다. 이러한 사용자가 한 명도 없다면 API를 훨씬 수월하게 변경할 수 있다. 하지만 **API의 노출 시간이 길어지고 사용자가 늘어나면 가장 무해할 듯한 변경도 일부 사용자의 소프트웨어를 망가뜨릴 수 있다.**

### 1.1.2 사례: 해시 순서
**해시 반복 순서\_hash iteration ordering\_**에 대해서 대부분의 프로그래머는 해시 테이블의 원소 순서가 겉으로 밝히지 않은 나름의 알고리즘에 의해 정해짐을 알고 있다. 하지만 그 알고리즘이 언제까지 유지될지 구체적인 정보를 아는 사람은 거의 없다. 중요하지 않은 사실 같더라도 지난 10\~10년 사이 컴퓨터 업계는 해시 테이블을 사용하여 많은 일을 경험했다.

- 해시 플러딩\_hash flooding\_ 공격 때문에 해시 반복 순서가 비결정적이어야 할 필요가 더욱 커졌다.
- 개선된 해시 알고리즘과 해시 컨테이너 연구로 얻은 효율 개선 효과를 보려면 해시 반복 순서에 변화를 줘야 한다.
- 하이럼의 법칙에 따라 (할 수 있다면) 해시 테이블의 순회 순서에 의존하는 프로그램을 작성하는 프로그래머가 나타날 것이다.

그 결과, 여러분 주변의 전문가 아무나 붙들고 ‘제 해시 컨테이너가 정해진 순서대로 결과를 낸다고 가정해도 되나요?’라고 묻는다면 아마도 ‘아니요’라고 답할 것이다. 여러분의 코드는 해시 컨테이너의 순서에 의존하지 않게 구현하더라도 다른 누군가의 코드가 그 순서에 **암묵적으로 의존하게끔 작성될 수도** 있다.

이는 **‘동작한다\_it works\_’와 ‘옳다\_it is correct\_’의 차이**를 보여주는 예다. 해시 컨테이너의 반복 순서에 의존하더라도 프로그램의 수명이 짧다면 기술적 문제를 전혀 겪지 않을 것이다. 반면 소프트웨어 엔지니어링 프로젝트에서는 이런 의존성은 위험 요인에 해당한다. 시간이 충분히 흐르면 반복 순서를 바꾸는 게 나을 만한 사건이 일어날 수 있다. 효율 개선, 보안 강화, 혹은 앞으로의 변화에 대응하기 위한 미래 지향적 데이터 구조로의 개선 등 여러 가지가 있을 수 있다. **변경할 가치가 있음이 명백해지면 관련 개발자들과 고객들이 감내해야 할 고통의 크기와 잘 저울질해야 한다.**

이러한 의존을 원천봉쇄하고자 실행할 때마다 해시 순서가 달라지게 만들어도 하이럼의 법칙에서 완전히 자유롭기는 어렵다. 해시 반복 순서가 무작위임을 눈치챈 누군가가 이를 난수 발생기로 사용할 수도 있기 때문이다. 이제 무작위성을 제거하면 이 개발자의 코드가 오작동할 것이다. **모든 열역학 시스템에서 엔트로피가 증가하듯 하이럼의 법칙은 모든 관측 가능한 행위에 적용된다.**

**‘당장 돌아가야 한다’라는 생각으로 작성한 코드**와 **‘언제까지고 작동해야 한다’라는 생각으로 작성한 코드**의 차이로 봤을 때 프로그래밍 스타일을 다음처럼 분류해볼 수 있다.
- 이용하는 API의 명세에 명시되지 않은, 즉 **언제든 변할 수 있는 기능을 사용하는 코드**는 ‘임시방편적인\_hacky\_’ 혹은 ‘기발한\_clever\_’ 코드이다.
- 반대로 **모범 사례를 따르고 미래에 대비한 코드**는 ‘클린\_clean\_’하고 ‘유지보수 가능한’ 코드이다.

둘 다 나름의 목적이 있지만, 어느 쪽을 선택할지는 **코드의 기대 수명에 크게 좌우**된다. 우리는 **‘기발한’**이 **칭찬**으로 느껴진다면 **프로그래밍**이라 하고, **질책**으로 느껴진다면 **소프트웨어 엔지니어링**이라 말한다.

### 1.1.3 ‘변하지 않기’를 목표로 하지 않는 이유
**시간과 변경에 대처해야 하는 이유**에 관한 이 모든 논의의 밑바탕에는 **‘변경은 피할 수 없다’라는 가정**이 깔려 있다. 그런데 **정말 그럴까?**

이 역시 상황에 따라 다르다. 대부분의 프로젝트는 세월이 충분히 흐르면 기반 환경을 모두 교체해야 할 것이다. 하지만 아무런 **외부 의존성 없이 작성된 순수한 C 언어 프로젝트라면** 리팩터링이나 난해한 업그레이드 없이 버틸 수도 있다. 이런 면에서 C 언어는 상당히 안정적이며, 이런 **안정성이야말로 C 언어를 선택하는 주된 이유** 중 하나이다.

하지만 **대부분의 프로젝트는 기반 기술의 변화를 훨씬 많이 겪는다.** 대다수의 프로그래밍 언어와 런타임은 C 언어보다 빠르게 변한다. 순수 C로 구현한 라이브러리조차 새로운 기능을 지원하기 위해 변화하여 라이브러리 사용자들에게 영향을 준다. 보안 문제는 프로세서, 네트워크 라이브러리, 애플리케이션 할 것 없이 모든 기술 제품에서 발견된다. 여러분의 **프로젝트가 의존하는 모든 기술에는 여러분이 사용하기 시작한 후에야 발견될 심각한 버그와 보안 구멍이 존재할 위험이 도사린다.** 아무것도 변하지 않으리라 가정하여 하트블리드\_Heartbleed_[^1] 패치를 적용하지 않거나 멜트다운과 스펙터\_Meltdown and Spectre_[^2] 같은 추측 실행\_speculative execution\_ 문제를 완화해두지 않으면 위험천만한 도박에 뛰어드는 꼴이다.

**효율 개선**은 상황을 더욱 복잡하게 만든다. 구글은 데이터센터를 비용 효율적인 장비들로 꾸리길 원한다(특히 CPU 효율 개선에 힘쓴다). 하지만 구글에서 오래전에 만들어둔 알고리즘과 데이터 구조는 최신 장비에서 효율이 떨어지기도 한다. 연결 리스트와 이진 검색 트리는 여전히 잘 동작하지만 CPU 클록과 메모리 지연시간의 격차가 점점 벌어지면서 ‘효율적인’ 코드의 모습이 변하고 있다. 그래서 **소프트웨어 설계도 제때 변경해주지 않으면 최신 하드웨어를 도입하는 효과가 퇴색된다.** 하위 호환되는 하드웨어라서 오래된 시스템도 여전히 구동되지만 그 시절 최적화 기법이 지금도 여전히 유효할지는 불확실하다는 뜻이다. 그래서 **최신 장비의 잠재력을 최대한 끌어 쓸 의지와 역량이 없다면 지불한 비용만큼의 효과를 얻지 못할지도 모른다.** 이처럼 효율성은 상당히 미묘한 문제다. 기존 설계가 완벽히 논리적이고 합리적인 모범 사례를 충실히 반영한 것일 수도 있기 때문이다. 그래서 적절한 변경이 뒷받침 되어야 새로운 선택지의 도입 효과가 극대화된다. 이처럼 이전 시스템에 문제가 없더라도 시간이 흐르면 변경을 진행할 이유가 자연스럽게 만들어지기도 한다.

**지속 가능성에 투자하지 않는 장기 프로젝트가 왜 위험한지**를 알고 이러한 문제들에 대응할 수 있어야 하며, 직접 작성한 시스템의 문제든 시스템이 이용하는 기반 기술에 국한된 문제든 상관없이 주어진 기회를 최대한 살려야 한다. **변경은 본질적으로 좋지 않으므로 변경을 위한 변경은 삼가야 하지만 변화에 대응할 수는 있어야 한다.** **언젠가는 바뀌어야 한다면 변경 시 비용이 적게 들도록** 하는 데 미리 투자할지도 고민해야 한다. **시스템 관리자**는 백업 테이프가 있다는 사실뿐 아니라, 실제로 상황이 닥쳤을 때 **복구를 정확히 어떻게 수행하는지와 그 비용까지** 알고 있어야 한다. 연습하여 숙달시켜야만 효율과 안정성을 높일 수 있을을 명심해야 한다.

## 1.2 규모 확장과 효율성
> 코드베이스의 수명이 다할 때까지 직면하는 변화가 몰고 오는 모든 변경을 안전하게 처리할 수 있다면 그 코드베이스는 지속 가능하다.
이 풀이에는 \*\*비용\_cost_**이라는 요소가 숨어 있습니다. **비용이 너무 많이 드는 변경은 지연되기 쉽다.\*\* 변경 비용이 시간 흐름보다 가파르게 상승하는 시스템은 분명 확장 가능\_scalable_(규모 확장에 따른 비용이 선형보다 더 완만하게 증가)하지 않는다. 시간이 흐르다 보면 결국은 예상치 못한 일이 발생하여 변경이 불가피한 시점이 올 것이다. 프로젝트 규모가 두 배로 커진 뒤에 똑같은 상황이 다시 닥치면 인력도 두 배만 투입하면 해결될까요? 그 시점에 필요한 인력을 거느리고 있을까요?

인건비 외에도 확장 가능해야 할 게 더 있다. 소프트웨어 자체는 연산\_compute\_, 메모리, 스토리지, 대역폭 같은 전통적인 자원을 더 추가할수록 비례하여 속도나 처리량이 확장되어야 한다. **소프트웨어 개발 비용도 인력 투입과 개발 워크플로를 떠받드는 컴퓨터 자원 증대에 맞춰 매끄럽게 확장되어야 한다.** 만약 테스트 클러스터용 컴퓨트 비용이 선형보다 가파르게 증가한다면 인당 컴퓨트 자원 소비량이 매 분기 늘어날 것이다. 지속할 수 없는 길로 접어들었으니 변화가 필요한 순간이다.

마지막으로 소프트웨어 조직에서 가장 중요한 자산인 **코드베이스 자체도 확장 가능해야 한다.** 코드가 많아지고 변경 이력이 쌓이는 등의 이유로 빌드 시스템이나 버전 관리 시스템이 점점 느려진다면 어느 순간 더는 정상 운영할 수 없는 시점이 온다. **‘전체 빌드에 걸리는 시간’, ‘리포지터리에서 전체를 새로 내려받는 시간’, ‘프로그래밍 언어 버전을 업그레이드하는 비용’ 같은 지표는 적극적으로 관리하지 않으면 천천히 악화된다.** 마치 ‘끊는 물 속의 개구리(물을 서서히 덥히면 그 안의 개구리는 뜨거워지는 줄 모르고 결국 죽게 된다는 옛 믿음이지만, 최근 실험에 따르면 정상적인 개구리는 25도에서 탈출을 시도한다고 한다)’ 처럼 서서히, 위험이 현실이 되는 순간까지 단 한 번도 눈치 채지 못할 수도 있다. 그래서 이런 문제들은 조직 차원에서 챙기며 확장 가능성에 신경 써야지만 안정되게 관리할 수 있다.

**조직에서 코드를 작성하고 관리하는 데 활용하는 모든 것이 총비용과 자원 소비 측면에서 확장 가능해야 한다. 특히 반복적으로 수행하는 일이라면 모두 인적 비용 측면에서 확장 가능해야 한다.** 흔하게 활용되는 정책 중에서도 이 관점에서 확장 가능하지 못한 경우가 제법 많다.

### 1.2.1 확장하기 어려운 정책들
- 조직이 10배로 커지면 이 작업도 10배로 많아지는가?
- 엔지니어가 해야 할 일의 양이 조직이 커질수록 늘어나는가?
- 코드베이스가 커질수록 작업량도 늘어나는가
- 이 중 하나에 해당할 경우 **작업을 자동화하거나 최적화할 수단이 있는가?**
마지막 질문의 답이 ‘아니오’라면 **확장성에 문제**가 있는 것이다.

기존 위젯을 제거하고 새로운 위젯으로 대체하는 것 처럼**시스템을 폐기\_deprecation\_** 시키는 방식은 작은 조직에서는 통할지 몰라도 의존성 그래프가 조금만 깊고 넓어지면 곧바로 실패하고 만다. 팀이 의존하는 위젯 수가 늘어나면 단 한 번의 빌드 실패가 영향을 미치는 범위도 함께 늘어난다. **이 문제를 ‘확장 가능한 방식으로 푼다’라고 함은 폐기를 처리하는 방식을 바꾼다는 뜻이다.** 마이그레이션 작업을 사용자에게 떠넘기는 대신 시스템 담당 팀 내부에서 스스로 처리할 수 있도록 하는 것이다. 그러면 사용자가 많아져도 노하우를 축적한 하나의 팀이 모두 처리하므로 규모의 경제 효과도 누릴 수 있다.

**인프라 팀**은 사내 사용자들이 **새 버전**으로 옮기도록 돕거나 직접 업데이트하되, **하위 호환성을 유지**해야 한다. 우리가 **‘갈아타기 규칙\_Churn Rule\_’**이라 부른 이 정책은 확실히 확장성이 더 뛰어났다. **사용자 입장에서는 새 인프라로 바꿔서 당장 얻는 이익이 눈에 보이지 않음에도(혹은 우선순위가 낮음에도) 자신들 보고 바꾸라고 하면 의욕이 떨어져서 적극적으로 움직이지 않기 때문이다.**

**마이그레이션을 담당하는 전문가 그룹을 따로 두는 편이 사용자 각자에게 유지보수를 부담시키는 방식보다 확장성이 좋았다.** 전문가들이 프로젝트 전체를 깊이 파악한 후, 그 전문성을 바탕으로 파생 문제들을 해결하는 식이다. 마이그레이션을 사용자가 알아서 대응하도록 하면 인프라 변경에 영향받는 모든 팀에서 사태를 파악하고, 당면한 문제를 해결하고, 더 이상 쓸모 없어진 옛 지식은 폐기해야 했다. 이것이 전문가 그룹의 확장성이 더 뛰어난 이유다.

**개발 브랜치**를 활용하는 전통적인 방법 역시 확장성 문제를 겪는 정책의 좋은 예가 된다. 큰 기능을 트렁크\_trunk\_(메인 개발 브랜치)로 병합하다가 제품이 불안정해지자 화들짝 놀라서 ‘앞으로 병합은 더 철저히 통제되고 빈도도 줄이겠다’라고 공표하는 조직도 있을 것이다. 이렇게 하면 곧 모든 팀과 모든 기능이 독립된 개발 브랜치로 나뉘게 된다. **모든 브랜치는 ‘완료’되려면 트렁크로 머지되고 테스트되어야 하므로 아직 다른 개발 브랜치에서 작업 중인 엔지니어들은 다시 동기화하고 테스트하느라 값진 시간을 허비하게 된다.** 브랜치가 5\~10 개 정도인 작은 조직이라면 이런 관리 정책도 문제없을 테지만, 조직이 커지고 브랜치 수가 늘어나면 머지않아 반복되는 작업에 엄청난 시간과 노력을 쏟아붓고 있는 모습을 발견할 것이다. 규모가 커지면 다른 방식이 필요하다.

### 1.2.2 확장 가능한 정책들
어떤 정책이라야 조직 성장에 따르는 비용이 적을까? 더 정확히 말해, **선형 증가보다 나은 정책들**의 공통된 특징은 무엇일까?

구글 내부 정책 중 인프라팀이 인프라 변경을 안전하게 진행하게끔 보호해주는 정책이 하나 있다. 바로 ‘인프라를 변경하여 서비스가 중단되는 등의 문제가 발생하더라도, 같은 문제가 **지속적 통합\_continuous integration, CI\_ 시스템의 자동 테스트에서 발견되지 않는다면 인프라팀의 책임이 아니다**’라는 정책이다. 이 정책의 이름은 ‘비욘세 규칙\_The Beyonce Rule\_’이며, 친근하게 표현하면 ‘네가 좋아했다면 CI 테스트를 준비해뒀어야지’라는 뜻이다. (**‘코드를 짰으면 자기 코드에 대한 테스트도 자기가 제대로 만들었어야지’**라는 뜻으로 해석할 수도 있다.) 공통 CI 시스템에 추가해두지 않은 테스트는 인프라팀이 책임지지 않는다는 뜻이다. 이 규칙이 없었다면 인프라팀의 엔지니어는 아마도 코드가 조금이라도 영향받은 모든 팀을 일일이 찾아다니며 그들이 어떻게 테스트하고 있는지를 물어봐야 했을 것이다. 엔지니어가 100명 남짓일 때는 가능했지만 지금 상황에서는 도저히 감당할 수 없는 방식이다.

우리는 **전문성과 공유 포럼**이 **조직 확장**에 기여하는 바가 크다는 사실을 깨달았다. 엔지니어들이 포럼에 질문하고 답하는 과정에서 **지식이 전파**되고 **새로운 전문가가 성장**한다. **100 명의 자바 엔지니어가 있는 조직에서 질문에 기꺼이 답해줄 전문가가 한 명만 있어도 곧 더 나은 자바 코드를 작성하는 100명의 엔지니어가 생겨난다.** 지식은 입에서 입을 타고 퍼지며 전문가들이 그 매개체인 것이다. 이 외에도 엔지니어들이 흔히 겪는 걸림돌들을 치우는 일의 가치에 관하여 할 말이 많다.

### 1.2.3 사례: 컴파일러 업그레이드
프로그래밍 언어들이 하위 호환성을 지키기 위해 들이는 막대한 노력을 감안한다면 컴파일러 업그레이드는 쉬운 일이어야 마땅하다. 이론적으로는 그렇다는 말이다. 하지만 실제 비용은 얼마나 들까? 이전에 비슷한 종류의 업그레이드를 경험해보지 못했다면 코드베이스가 새로운 컴파일러와 얼마나 호환될지를 어떻게 예측할 수 있을까?

경험상 하위 호환성이 좋다고 알려진 경우라도 언어와 컴파일러의 업그레이드는 섬세하고 어려운 과제이다. **컴파일러가 업그레이드될 때는 거의 항상 어딘가 미묘하게 다르게 동작하는 곳이 있기 마련이다.** 예컨대 **오류를 수정하거나, 최적화 방식을 바꾸거나, 모호하던 어떤 동작을 명확하게 정의해 넣기도** 한다. 이런 숨은 변경들이 우리의 코드베이스 전체에 얼마나 영향을 줄지를 어떻게 평가해야 할까?

2006년 구글은 앞선 5년 동안 컴파일러를 업그레이드하지 않아서 대부분의 엔지니어가 컴파일러를 변경해본 경험이 없고 작성된 코드들도 단 하나의 컴파일러 버전만 겪어본 상태였다. 그래서 당시 업그레이드는 (대부분) 지원자들로 구성된 팀에게 **악몽과도 같은 작업**이었는데, 결국은 컴파일러와 언어의 변경사항 중 적용할 방법을 찾지 못한 것들의 **우회법과 단순화 트릭을 찾는 일로 변질**되었다. 그 결과 2006년의 컴파일러 업그레이드는 끔찍한 경험을 선사했다. 코드베이스에서는 크고 작은 하이럼의 법칙 문제들이 튀어나와서 특정 컴파일러 버전에 더 깊이 의존하게 만들었다. 이 의존성들을 끊기가 아주 고통스러웠는데, 문제가 생긴 코드의 담당 엔지니어들이 해결해야 했다. 당시는 비욘세 규칙도 없었고 CI 시스템도 널리 보급되지 않은 시절이었다. 그래서 컴파일러 변경이 초래할 영향을 사전에 알기 어려웠고 회귀 문제(제대로 작동하던 기능이 오작동하는 문제를 말하며 일반적으로 기능 추가, 리팩토링, 버그 수정 등 다른 목적으로 코드를 수정하는 과정에서 뜻하지 않게 일어난다)를 일으키지 않으리라 보장할 수도 없었다.

구글은 이러한 고통을 겪고 난 후에야 **규모 문제를 극복할 기술**을 찾고 **조직을 변화**시켜서 **큰 규모가 장점이 되도록 하기 위해 노력**했다. 그 노력은 **자동화(한 사람이 더 많은 일을 수행), 통합과 일관성(저수준 변경이 영향을 미치는 범위 제한), 전문성(적은 인원으로 더 많은 일을 수행)**으로 이어졌다.

**인프라는 더 자주 변경할수록 변경하기가 오히려 쉬워진다.** 우리는 컴파일러 업그레이드 등의 목적으로 코드를 한 번 수정해두면 **거의 예외 없이 코드가 더 견고해지고 다음번 업그레이드하기도 쉬워진다**는 사실을 깨달았다. 시스템을 구성하는 각 요소의 코드가 **이런 수정을 여러 차례 거치고 나면 하부 구현의 미묘한 차이에 의존하는 일이 없어지고, 대신 언어나 OS 차원에서 보장하는 추상 개념을 활용하도록 바뀐다.** 여러분이 무엇을 업그레이드하든, 그 외의 요소를 아무리 잘 통제하더라도 결국 첫 번째 업그레이드 때의 코드베이스 수정량이 압도적으로 가장 많을 것이다.

#### 업그레이드를 통해 코드베이스의 유연성에 영향을 주는 요인들
- 전문성\_expertise\_: 수많은 플랫폼에서 수백 번의 컴파일러 업그레이드로 충분한 지식을 갖췄다.
- 안정성\_stability\_:  더 규칙적으로 릴리스하여 릴리스 사이의 변경량을 줄였다.
- 순응\_conformity\_:  규칙적인 업그레이드의 도움으로 업그레이드를 겪지 않은 코드가 많지 않다.
- 익숙함\_famillarity\_: 업그레이드를 정기적으로 수행하기 때문에 그 과정에서 중복되는 작업을 찾고 자동화 하려고 노력했다.
- 정책\_policy\_: 비욘세 규칙과 같은 유용한 정책과 절차를 갖춘다. 이러한 정책들 덕분에 인프라팀은 미지의 사용 방법까지 걱정할 필요 없이 업그레이드를 진행할 수 있다. CI 시스템에 반영된 사용법만 고민하면 된다.

컴파일러를 업그레이드해야만 하는 상황에 직면했을 때, 코드베이스가 계속 커지더라도 일정한 수의 엔지니어만으로 업그레이드를 성공적으로 해내는 방법을 찾을 수 있다. 만약 구글이 첫 번째 경험에서 치른 비용이 너무 커서 이후의 컴파일러 업그레이드를 포기했다면 여전히 **10년도 더 전의 컴파일러**를 사용하고 있었을지 모른다. 정말 그랬다면 그 사이 발전한 최적화 기법의 효과를 누릴 수 없어서 **컴퓨팅 자원을 25%는 더 쓰고 있었을지** 모를 일이다. 2006년의 컴파일러가 추측 실행 취약점을 완화하는 데 도움 될 리 만무하니 구글의 핵심 인프라는 심각한 **보안 위협에 노출**되어 있었을 것이다. **그대로 두자는 의견도 존중해야겠지만 보통은 현명하지 못한 선택일 것이다.**

### 1.2.4 원점 회귀(왼쪽으로 옮기기)
**개발 과정에서 문제를 일찍 발견할수록 비용이 적게 든다**는 사실은 널리 받아들여지는 진실이다.

어떤 기능의 개발자 워크플로를 시간순으로 생각해보면 컨셉워크와 설계에서 시작하여 구현, 리뷰, 테스트, 커밋, 카나리\_canary\_를 거쳐 최종적으로 프로덕션 환경에 배포하게 된다. 이 타임라인에서 문제 발견 시점을 왼쪽으로 이동시킬수록 수정 비용이 줄어든다.
왼쪽으로 옮기는 행위를 **원점 회귀\_shift left\_**라 하는데, 보안성 점검을 개발 프로세스의 마지막으로 연기하면 안 된다고 호소하며 ‘보안을 고려하는 시점을 왼쪽으로 이동시켜라\_shift left on security\_’라고 한 말에서 유래한 듯 하다. 제품을 고객에게 배포한 후에야 취약점이 발견되면 해결하는 데 막대한 비용이 들 것이다. 다행히 프로덕션 배포 직전에 발견하면 문제를 식별하고 조치하는 데 여전히 큰 비용이 들겠지만 훨씬 저렴할 것이다. 담당 개발자는 기능과 코드를 잘 이해하고 있으니 어느 부분을 어떻게 수정해야 하는지를 훨씬 쉽게 알 수 있기 때문이다.

**코드 커밋 전에 정적 검사나 코드 리뷰로 찾아낸 버그**는 **프로덕션 이후에 발견한 버그**보다 훨씬 싸게 고칠 수 있다. 그래서 개발 프로세스 초기에 품질, 안정성, 보안 문제를 찾아 알려주는 도구와 관례를 제공하는 일은 구글 인프라 팀의 주요 목표 중 하나이다. **완벽한 단 하나의 절차나 도구는 존재하지 않는다.** 그래서 가능한 한 많은 버그를 그래프 왼쪽에서 잡기를 바라며 **다층 방어\_defense-in-depth\_** 전략을 구사한다.

## 1.3 트레이드오프와 비용
프로그래밍하는 방법과 소프트웨어의 라이프 사이클을 이해했고, 새 기능을 추가하고 관리할 엔지니어를 더 고용하면서도 제품을 온전히 유지보수하는 방법을 깨우쳤다면, 남은 것은 **좋은 결정을 내리는 일** 뿐이다. 인생이 그러하듯 소프트웨어 엔지니어링에서도 **좋은 선택이 대체로 좋은 결과로 이어진다. 하지만 결정에 이르는 과정은 쉽게 간과되곤 한다.** 구글에서는 ‘내가 시켰으니까’ 방식을 아주 싫어한다.  물론 어떤 주제든 한 명의 결정권자를 두고, **잘못된 결정이라 판단될 때 찾아가야 할 사람들의 에스컬레이션 경로\_escalation path, 결재 라인\_**도 명확히 정의해야 한다. 하지만 그 목표는 **독재가 아니라, 어디까지나 합의를 도출**하는 데 있다.

**비용\_cost\_**은 금액만을 지칭하는 게 아니다. 투입된 노력과 다음의 요소들까지 모두 포괄한다.
- 금융 비용 (ex: 돈)
- 리소스 비용 (ex: CPU 시간)
- 인적 비용 (ex: 엔지니어링 노력)
- 거래 비용 (ex: 조치를 취하는 비용)
- 기회 비용 (ex: 조치를 취하지 않는 비용)
- 사회적 비용 (ex: 선택이 사회 전체에 미치는 영향)

역사적으로 **사회적 비용 문제**는 무시되기 일쑤였다. 하지만 구글과 같은 거대 기업에서는 수십억 명이 사용하는 제품을 배포하는 일이 드물지 않다. 이 제품들은 확실한 이윤을 가져다주는 게 보통이지만, 이런 규모로 운영하다보면 **사용성, 접근성, 공정성, 남용 가능성에서의 작은 문제**조차 때로는 **간신히 유지되던 사회 집단에 치명적인 피해**를 주곤 한다. **소프트웨어는 다양한 측면에서 현재 사회와 문화에 강하게 융합되어 있다.** 따라서 우리가 만들 제품의 기술적 결정이 초래할 **이로운 점**과 **해로운 점** 모두를 인지해야 한다.

앞에 나열한 비용(과 추정치) 외에도 **현상 유지 편향\_status quo bias_**과 **손실 회피_loss aversion_** 같은 치우침_bias_도 존재한다. **비용을 평가할 때**는 앞에서 열거한 모든 비용을 염두에 두어야 한다. **조직의 건실성**에는 **은행 잔고**뿐 아니라 **구성원들이 스스로의 가치를 느끼고 생산적인 일을 하고 있다고 생각하는지**까지 포함된다. 소프트웨어 엔지니어링처럼 매우 창의적이고 수익성 높은 분야에서는 **금융 비용보다는 인적 비용이 제한 요소일 가능성이 크다.** 그래서 **엔지니어들이 행복을 느끼게 만들고 일에 집중하고 참여할 수 있게 해주면 효율이 높아진다. 집중력이 생산성에 미치는 영향은 아주 커서 10\~20%의 차이는 우습게 만들어낸다.**

### 1.3.1 사례: 화이트보드 마커
많은 조직에서 화이트보드 마커는 귀중하게 대접받는다. 엄격하게 관리되며 항상 공급이 부족하죠. 어느 화이트보드에 가서 찾든 구비된 마커의 절반은 말라 있거나 사용할 수 없는 상태이다. **회의 때 제대로 나오는 마커가 부족해서 방해된 적이 몇 번 인요? 마커가 나오다 말아서 사고의 흐름이 끊겨본 경험은?** 나오는 마커가 하나도 없던 경험은? **고작 천 원도 안 되는 제품** 때문에 흔히 겪는 일이다.

구글은 사무용품과 일상적인 개발 시 드는 경비부터 글로벌 규모의 서비스를 준비하고 운영하는 방법에 이르기까지, **우리가 하는 모든 일과 관련한 비용/이윤 트레이드오프에 동일한 수준의 관심을 두고 명확히 계량하려 한다.** 종종 ‘구글의 문화는 데이터 주도적이다’라고 하는데, 실상은 데이터가 없을 때조차 **근거, 선례, 논증을 거쳐 결정**을 내리곤 한다. **좋은 엔지니어링적 결정**이란 결국 **가용한 모든 근거 자료에 적절한 가중치를 부여하고, 이러한 풍부한 지식을 바탕으로 균형점을 잡는 일**이다. **때로는 본능과 잘 알려진 모범 사례에 의지**해 결정하기도 하지만, 보통은 **실제 비용을 추정하고 예측해보려 시도**해본 뒤에 그렇게 한다.

결국 엔지니어링 조직의 선택을 결정짓는 요인은 다음의 몇 가지로 압축된다.
- **반드시 해야 하는 일(법적 요구사항, 고객 요구사항)**
- **근거에 기반하여 당시 내릴 수 있는 최선의 선택(적절한 결정권자가 확정)**

의사결정이 ‘내가 시켰으니까’가 되어서는 안 된다.
(만장일치나 대다수가 합의해야만 한다고 말하는 게 아니다. 결국 결정권자는 필요하다. 실제 결정권자가 누구든 상관없이 의사결정 프로세스가 어떻게 이러워져야 하는가를 이야기하는 표현이다.)

### 1.3.2 의사결정을 위한 근거 자료
**근거 자료의 가중치를 정하는 시나리오**는 주로 다음의 두 가지이다.
1. **관련한 정략적 데이터를 모두 ‘측정’할 수 있거나 최소한 ‘추정’이라도 할 수 있는 경우**이다. CPU와 네트워크, 금액과 메모리 양 사이의 트레이드오프를 평가할 때, 혹은 여러 데이터센터에 설치할 CPU N개를 줄이기 위해 엔지니어를 두 주 정도 투입할지 고민할 때가 여기에 해당된다.
2. **측정하기 어렵거나 측정 방법을 모르는 정량적 데이터**도 있다. 때로는 **‘엔지니어 시간이 얼마나 들지 모르겠다’**라는 표현으로, 때로는 더 모호하게 표현되곤 한다. 후자의 예로는 ‘엉망으로 설계된 API의 엔지니어링 비용을 측정할 방법은?’이나 ‘선택한 제품의 사회적 영향은?’ 같은 질문이 있다.

첫 번째 결정 유형에서는 결함이 파고들 여지가 적다. **모든 소프트웨어 엔지니어링 조직은 연산 자원, 엔지니어 시간, 그 외 정기적으로 활용하는 다른 정량적 데이터의 현재 비용을 추적하고 관리할 수 있어야 하고, 관리해야 한다. **예컨대 특정 개수의 CPU를 기준으로 정한 다음, 같은 가치에 해당하는 메모리 양이나 네트워크 대역폭을 표로 정리해둘 수 있다.
합의된 환산표가 갖춰진다면 모든 엔지니어가 자신에게 필요한 분석을 할 수 있다. **‘내가 두 주 동안 이 연결 리스트를 고성능 데이터 구조로 변환한다면 프로덕션 시스템의 메모리 5GB를 더 쓰지만 필요한 CPU 수를 2,000개 줄일 수 있어. 진행해야 할까?’** 이 물음에 답하려면 메모리와 CPU의 상대적 비용은 물론, 나아가 인건비(소프트웨어 엔지니어가 2주 간 작업)와 기회 비용(2주 동안 엔지니어가 할 수 있는 다른 일)까지 고려해야 합니다.

두 번째 결정 유형에서는 쉬운 답이 나오기 어렵다. 그래서 **절충안을 찾기 위해 경험, 리더쉽, 선례에 기대야 한다.** 우리가 줄 수 있는 가장 보편적인 제안은 **모든 것이 측정 가능하거나 예측 가능하지는 않다는 사실을 인정하고, 그런 결정에도 똑같은 우선순위와 관심을 두라**는 것이다. 그래서 두 번째 유형도 똑같이 중요하지만 관리하기는 더 어렵다.

### 1.3.3 사례: 분산 빌드
전혀 과학적이지 않은 트위터 여론 조사에 따르면 소프트웨어가 거대해진 오늘날에도 약 60\~70%의 개발자가 빌드를 로컬에서 실행한다고 한다. 여러분의 조직에서는 빌드가 끝나기를 기다리느라 얼마나 많은 생산적인 시간을 낭비하고 있나요? 그 시간을 작은 그룹에서 distcc(코드를 네트워크상의 여러 컴퓨터에 나눠 빌드하는 C/C++용 분산 컴파일러)를 활용할 때의 비용과 비교해봐라. 혹은 큰 그룹에서 **작은 빌드 팜_build farm_을 운영하는 비용은 얼마나 될까? 그 비용이 순이익이 되기까지는 몇 주 혹은 몇 달이 걸릴까?**


[^1]:	https://heartbleed.com

[^2]:	Https://meltdownattack.com

